{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from config import max_letters, language_tags\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_vector(lst, max_word_length):\n",
    "    new_list = []\n",
    "    for item in lst:\n",
    "        vec = ''\n",
    "        n = len(item)\n",
    "        for x in range(n):\n",
    "            current_letter = item[x]\n",
    "            ind = ord(current_letter)-97\n",
    "            placeholder = (str(0)*ind) + str(1) + str(0)*(25-ind)\n",
    "            vec = vec + placeholder\n",
    "        if n < max_word_length:\n",
    "            excess = max_word_length-n\n",
    "            vec = vec + str(0)*26*excess\n",
    "        new_list.append(vec)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thili\\Anaconda3\\envs\\fyp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(200, input_dim=26*max_letters, activation='sigmoid'))\n",
    "network.add(Dense(150, activation='sigmoid'))\n",
    "network.add(Dense(100, activation='sigmoid'))\n",
    "network.add(Dense(100, activation='sigmoid'))\n",
    "network.add(Dense(len(language_tags), activation='softmax'))\n",
    "network.load_weights('weights.hdf5')\n",
    "network.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lang_nn(word):\n",
    "    dic = []\n",
    "    scores = []\n",
    "    if len(word) <= max_letters:\n",
    "        word = word.lower()\n",
    "        word = unidecode(word)\n",
    "    dic.append(word)\n",
    "    vct_str = convert_word_to_vector(dic, max_letters)\n",
    "    vct = np.zeros((1, 26 * max_letters))\n",
    "    count = 0\n",
    "    for digit in vct_str[0]:\n",
    "        vct[0, count] = int(digit)\n",
    "        count += 1\n",
    "    prediction_vct = network.predict(vct)\n",
    "    langs = list(language_tags.keys())\n",
    "    for i in range(len(language_tags)):\n",
    "        lang = langs[i]\n",
    "        scores.append(prediction_vct[0][i])\n",
    "    final_out = [0,0]\n",
    "    for i in range(len(language_tags)):\n",
    "        if(final_out[0]<scores[i]):\n",
    "            final_out[0] = scores[i];\n",
    "            final_out[1] = i\n",
    "    return langs[final_out[1]]\n",
    "\n",
    "def predict_lang_uni(word):\n",
    "    si_count = 0\n",
    "    en_count = 0\n",
    "    other_count = 0\n",
    "\n",
    "    for char in word:\n",
    "        ord_val = ord(char)\n",
    "        if (65 <= ord_val <= 90) or (97 <= ord_val <= 122):\n",
    "            en_count += 1\n",
    "        elif 3456 <= ord_val <= 3583:\n",
    "            si_count += 1\n",
    "        else:\n",
    "            other_count += 1\n",
    "\n",
    "    si_presen = si_count / len(word)\n",
    "    en_presen = en_count / len(word)\n",
    "    other_presen = other_count / len(word)\n",
    "\n",
    "    lang_dict = {'si': si_presen, 'en': en_presen, 'other': other_presen}\n",
    "\n",
    "    return max(lang_dict, key=lang_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('test_data_sets/test_set.xlsx', sep=\" \")\n",
    "## data = data.dropna()\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating NN model\n",
    "en_en_nn = 0\n",
    "en_si_nn = 0\n",
    "si_si_nn = 0\n",
    "si_en_nn = 0\n",
    "\n",
    "for i in range(len(data['word'])):\n",
    "    try:\n",
    "        if(len(data['word'][i])<=max_letters):\n",
    "            prediction = predict_lang_nn(data['word'][i])\n",
    "            if(data['tag'][i]=='en'):\n",
    "                if(prediction == 'en'):\n",
    "                    en_en_nn += 1\n",
    "                elif(prediction == 'si'):\n",
    "                    en_si_nn += 1\n",
    "#                     print (data['word'][i])\n",
    "            elif(data['tag'][i]=='si'):\n",
    "                if(prediction == 'si'):\n",
    "                    si_si_nn += 1\n",
    "                elif(prediction == 'en'):\n",
    "                    si_en_nn += 1\n",
    "#                     print (data['word'][i])\n",
    "    except:\n",
    "         continue\n",
    "            \n",
    "## Evaluating Unicode model\n",
    "en_en_uni = 0\n",
    "en_si_uni = 0\n",
    "si_si_uni = 0\n",
    "si_en_uni = 0\n",
    "\n",
    "for i in range(len(data['word'])):\n",
    "    try:\n",
    "        if(len(data['word'][i])<=max_letters):\n",
    "            prediction = predict_lang_uni(data['word'][i])\n",
    "            if(data['tag'][i]=='en'):\n",
    "                if(prediction == 'en'):\n",
    "                    en_en_uni += 1\n",
    "                elif(prediction == 'si'):\n",
    "                    en_si_uni += 1\n",
    "#                     print (data['word'][i])\n",
    "            elif(data['tag'][i]=='si'):\n",
    "                if(prediction == 'si'):\n",
    "                    si_si_uni += 1\n",
    "                elif(prediction == 'en'):\n",
    "                    si_en_uni += 1\n",
    "#                     print (data['word'][i])\n",
    "    except:\n",
    "         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14635 4987 17673 3800\n",
      "NN Model Evauation | Let English as Positive\n",
      "Accuracy :  0.786178367197956\n",
      "Precision :  0.7458464988278463\n",
      "Recall :  0.7938703553024139\n"
     ]
    }
   ],
   "source": [
    "print(en_en_nn,en_si_nn,si_si_nn,si_en_nn)\n",
    "print (\"NN Model Evauation | Let English as Positive\")\n",
    "accuracy_nn  = (en_en_nn + si_si_nn )/(en_en_nn  + en_si_nn  + si_en_nn  + si_si_nn )\n",
    "precision_nn  = en_en_nn /(en_en_nn  + en_si_nn )\n",
    "recall_nn  = en_en_nn /(en_en_nn  + si_en_nn )\n",
    "print (\"Accuracy : \", accuracy_nn )\n",
    "print (\"Precision : \", precision_nn )\n",
    "print (\"Recall : \", recall_nn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode Model Evauation | Let English as Positive\n",
      "Accuracy :  0.9832836360350592\n",
      "Precision :  0.9809733627077909\n",
      "Recall :  0.9819566960705693\n"
     ]
    }
   ],
   "source": [
    "print (\"Unicode Model Evauation | Let English as Positive\")\n",
    "accuracy_uni  = (en_en_uni + si_si_uni )/(en_en_uni  + en_si_uni  + si_en_uni  + si_si_uni )\n",
    "precision_uni  = en_en_uni /(en_en_uni  + en_si_uni )\n",
    "recall_uni  = en_en_uni /(en_en_uni  + si_en_uni )\n",
    "print (\"Accuracy : \", accuracy_uni )\n",
    "print (\"Precision : \", precision_uni)\n",
    "print (\"Recall : \", recall_uni )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fyp)",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
